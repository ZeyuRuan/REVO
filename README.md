# Robust Edge-based Visual Odometry (REVO)

This project is based on REVO work by Schenk Fabian, Fraundorfer Friedrich.
 
## If you use this work, please cite any of the following publications:
* **Combining Edge Images and Depth Maps for Robust Visual Odometry**, Schenk Fabian, Fraundorfer Friedrich, BMVC 2017, [pdf](https://pure.tugraz.at/portal/files/10383987/0661.pdf),[video](https://youtu.be/uj3rRyqSEnQ)
* **Robust Edge-based Visual Odometry using Machine-Learned Edges**, Schenk Fabian, Fraundorfer Friedrich, IROS 2017, [pdf](https://pure.tugraz.at/portal/files/11216598/schenk_paper_final.pdf), [video](https://youtu.be/PUTV9vsdpbA)

In this work, a robust edge-based visual odometry (REVO) system is presented for RGBD sensors. Edges are more stable under varying lighting conditions than raw intensity values, which leads to higher accuracy and robustness in scenes, where feature- or photoconsistency-based approaches often fail. The results show that this method performs best in terms of trajectory accuracy for most of the sequences indicating that edges are suitable for a multitude of scenes.

## License
REVO is licensed under the [GNU General Public License Version 3 (GPLv3)](http://www.gnu.org/licenses/gpl.html).

## Building the framework

This framework is built and tested on the following system.
### Requirements
* [Ubuntu](https://www.ubuntu.com/)
* [OpenCV > 4](http://opencv.org/)
* [Eigen > 3.3](http://eigen.tuxfamily.org/index.php?title=Main_Page)
* [Sophus](https://github.com/strasdat/Sophus) included in this repository(/thirdparty/Sophus)
* [Pangolin](https://github.com/stevenlovegrove/Pangolin)  (for graphical viewer)

### Optional
Set the optional packages in the cmake-gui
* Intel RealSense ZR300 (see below)
* Orbbec Astra Pro (see below)

### Build commands
```bash
git clone REVO
cd REVO; mkdir build; cd build
cmake . ..
make -j
```

### Dataset
This project works on input RGBD files and tested on [TUM dataset](https://vision.in.tum.de/data/datasets/rgbd-dataset), of which generated by Microsoft Kinnect RGBD cameras. 
Download the sequence you want to test and generate an "associate.txt" file to align the rgb image and depth image. To generate an "associate.txt" file, first download the "associate.py" script from [TUM RGBD Tools](https://svncvpr.in.tum.de/cvpr-ros-pkg/trunk/rgbd_benchmark/rgbd_benchmark_tools/src/rgbd_benchmark_tools/) (actually already included in the "dataset" directory) and then run
```bash
python associate.py DATASET_XXX/rgb.txt DATASET_XXX/depth.txt > associate.txt
```
in the dataset directory. 

After generating the "associate.txt" file, move it to your dataset directory. Then specify the path to dataset and associate.txt in the dataset_tumX.yaml settings file(in /config).
To run the dataset: 
In the "REVO" directory
```bash
build/REVO config/revo_settings.yaml config/dataset_tum1.yaml
```
There're many setting parameters in these two '.yaml' files.
 
* In "/config/revo_settings.yaml", "DO_GENERATE_DENSE_PCL" is for image pyrimid to improve sparse area and "DO_GAUSSIAN_SMOOTHING_BEFORE_CANNY" is for Gaussian blur before canny edge detection. They have been all set to 1, and you can change their value to 0 to compare the result. 
* In "/config/data_tum1.yaml", you must modify your path to the mainfolder, subfolder of dataset and the associate.txt. Also, you should check the type of camera(like freiburg1, observed by the dataset name) and modify the camera parameters if necessary. The camera parameters can be searched on the above TUM website. 

For evaluation of the absolute trajectory error (ATE) and relative pose error (RPE) download the corresponding scripts from [TUM RGBD Tools](https://svncvpr.in.tum.de/cvpr-ros-pkg/trunk/rgbd_benchmark/rgbd_benchmark_tools/src/rgbd_benchmark_tools/).

## Supported Sensors(not tested yet)
REVO supports three different sensors at the moment:
* [Orbbec Astra Pro Sensor](https://orbbec3d.com/product-astra-pro/)
* [Orbbec Astra Sensor](https://orbbec3d.com/product-astra/)
* [Intel Realsense ZR300 (other versions are untested!)](https://click.intel.com/intelr-realsensetm-development-kit-featuring-the-zr300.html)

For the Intel sensor set "WITH_REALSENSE", for the Orbbec Astra Pro set "WITH_ORBBEC_FFMPEG" (recommended) or "WITH_ORBBEC_UVC" (not recommended, requires third party tools) and for the non-pro Orbbec Astra set "WITH_ORBBEC_OPENNI"!
**Note:** Make sure that you set the USB rules in a way that the sensor is accessible for every user (default is root only).

REVO can be compiled for all three sensors only if WITH_REALSENSE, WITH_ORBBEC_FFMPEG and WITH_ORBBEC_OPENNI are set.
If WITH_ORRBEC_UVC is set, there is a conflict with the librealsense!
To solve this issue, use WITH_ORBBEC_FFMPEG!

The sensor to be used is determined from the INPUT_TYPE set in the second config file.
For Orbbec Astra Pro INPUT_TYPE: 1, for Intel Realsense INPUT_TYPE: 2 and for Orbbec Astra INPUT_TYPE: 3.

Example config files for all three sensors can be found in the config directory!
### Intel RealSense ZR300
Install [librealsense](https://github.com/IntelRealSense/librealsense), set the intrinsic parameters in the config file.
This framework was tested with the Intel RealSense ZR300.

### Orbbec Astra Sensor
The (non-pro) Orbbec Astra Sensor can be fully accessed by Orbbec's OpenNI driver.
First [download the openni driver](https://orbbec3d.com/develop/#registergestoos) and choose the correct *.zip file that matches your architecture, e.g. OpenNI-Linux_x64-2.3.zip. 
Extract it and copy libOpenNI2.so and the "Include" and "OpenNI2" folder to REVO_FOLDER/orbbec_astra_pro/drivers. 

### Orbbec Astra Pro Sensor
#### With FFMPEG
The standard OpenNI driver can only access the depth stream of the [Orbbec Astra Pro Sensor](https://orbbec3d.com/product-astra-pro/), thus we have to access the color stream via FFMPEG.
Install the newest FFMPEG version
```bash
sudo apt install ffmpeg
```
or download from [FFMPEG Github](https://www.ffmpeg.org/download.html).
#### With LibUVC (not recommended)
The standard OpenNI driver can only access the depth stream of the [Orbbec Astra Pro Sensor](https://orbbec3d.com/product-astra-pro/), thus we have to access the color stream like a common webcam.
*Note: We use libuvc because the standard webcam interface of [OpenCV](http://opencv.org/) buffers the images and doesn't always return the newest image.*

First [download the openni driver](https://orbbec3d.com/develop/#registergestoos) and choose the correct *.zip file that matches your architecture, e.g. OpenNI-Linux_x64-2.3.zip. 
Extract it and copy libOpenNI2.so and the "Include" and "OpenNI2" folder to REVO_FOLDER/orbbec_astra_pro/drivers. 

Then install [Olaf Kaehler's fork of libuvc](https://github.com/olafkaehler/libuvc) by performing the following steps in the main directory.
```bash
cd ThirdParty
git clone https://github.com/olafkaehler/libuvc
cd libuvc
mkdir build
cd build
cmake . ..
make -j
make install
```
## Troubleshooting
### Sophus
There was a problem with the old REVO version and a new Sophus version that introduced orthogonality checks for rotation matrices. 
If you face such an error, simply check out the current version of REVO.
### Orbbec with LIBUVC and Intel Realsense
If WITH_ORRBEC_UVC is set, there is a conflict with the librealsense! To solve this issue, use WITH_ORBBEC_FFMPEG!
